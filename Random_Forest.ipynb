{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKwuQCDVgUtp5O0+TMV2CS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RitikaHiremath/DataScience/blob/main/Random_Forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omHWV6IaVPhM",
        "outputId": "fa57e9e7-0c02-4206-e40a-b46b75c6503f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def load_and_label_data(base_path, label, max_files=None):\n",
        "    combined_100KHzdata = []\n",
        "    combined_2000KHzdata = []\n",
        "\n",
        "    # Initialize a counter\n",
        "    file_counter = 0\n",
        "\n",
        "    # Iterate over each timestamped folder\n",
        "    for timestamp_folder in os.listdir(base_path):\n",
        "        if max_files and file_counter >= max_files:\n",
        "            break\n",
        "\n",
        "        timestamp_folder_path = os.path.join(base_path, timestamp_folder, \"raw\")\n",
        "\n",
        "        # Extract the full timestamp from the folder name and convert to datetime format\n",
        "        timestamp = timestamp_folder.split('_')[0] + '_' + timestamp_folder.split('_')[1]\n",
        "        timestamp = pd.to_datetime(timestamp, format='%Y.%m.%d_%H.%M.%S')\n",
        "\n",
        "        # Load the 2000KHz data\n",
        "        df_2000KHz = pd.read_parquet(os.path.join(timestamp_folder_path, \"Sampling2000KHz_AEKi-0.parquet\"))\n",
        "        mean_2000KHz = df_2000KHz.mean().to_frame().T\n",
        "        mean_2000KHz['timestamp'] = timestamp\n",
        "        mean_2000KHz['label'] = label\n",
        "\n",
        "        # Load the 100KHz data\n",
        "        df_100KHz = pd.read_parquet(os.path.join(timestamp_folder_path, \"Sampling100KHz_Irms_Grinding-Grinding spindle current L1-Grinding spindle current L2-Grinding spindle current L3-0.parquet\"))\n",
        "        mean_100KHz = df_100KHz.mean().to_frame().T\n",
        "        mean_100KHz['timestamp'] = timestamp\n",
        "        mean_100KHz['label'] = label\n",
        "\n",
        "        # Append the mean data to the combined lists\n",
        "        combined_100KHzdata.append(mean_100KHz)\n",
        "        combined_2000KHzdata.append(mean_2000KHz)\n",
        "\n",
        "        # Increment the counter\n",
        "        file_counter += 1\n",
        "\n",
        "    # Combine all the mean data into a single dataframe\n",
        "    final_combined_100KHzdata = pd.concat(combined_100KHzdata, ignore_index=True)\n",
        "    final_combined_2000KHzdata = pd.concat(combined_2000KHzdata, ignore_index=True)\n",
        "\n",
        "    return final_combined_100KHzdata, final_combined_2000KHzdata\n",
        "\n",
        "# Define the paths to the OK and NOK data directories\n",
        "ok_data_path = '/content/gdrive/MyDrive/Data/OK_Measurements'\n",
        "nok_data_path = '/content/gdrive/MyDrive/Data/NOK_Measurements'\n",
        "\n",
        "# Load OK and NOK data\n",
        "ok_100KHzdata, ok_2000KHzdata = load_and_label_data(ok_data_path, label=0)\n",
        "nok_100KHzdata, nok_2000KHzdata = load_and_label_data(nok_data_path, label=1)\n",
        "\n",
        "# Combine OK and NOK data\n",
        "all_100KHzdata = pd.concat([ok_100KHzdata, nok_100KHzdata], ignore_index=True)\n",
        "all_2000KHzdata = pd.concat([ok_2000KHzdata, nok_2000KHzdata], ignore_index=True)\n",
        "\n",
        "# Print the first few rows of the combined data for inspection\n",
        "print(\"Combined 100KHz Data Sample (Mean):\")\n",
        "print(all_100KHzdata.head())\n",
        "print(\"\\nCombined 2000KHz Data Sample (Mean):\")\n",
        "print(all_2000KHzdata.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVkivTPkVuLS",
        "outputId": "ae414b3e-fc28-4233-826e-8668bcac170d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined 100KHz Data Sample (Mean):\n",
            "   Irms_Grinding_rate100000_clipping0_batch0  \\\n",
            "0                                   0.085166   \n",
            "1                                   0.085681   \n",
            "2                                   0.085834   \n",
            "3                                   0.085607   \n",
            "4                                   0.085260   \n",
            "\n",
            "   Grinding spindle current L1_rate100000_clipping0_batch0  \\\n",
            "0                                          -0.000076         \n",
            "1                                          -0.000062         \n",
            "2                                          -0.000078         \n",
            "3                                          -0.000086         \n",
            "4                                          -0.000060         \n",
            "\n",
            "   Grinding spindle current L2_rate100000_clipping0_batch0  \\\n",
            "0                                           0.000064         \n",
            "1                                           0.000100         \n",
            "2                                           0.000069         \n",
            "3                                           0.000083         \n",
            "4                                           0.000088         \n",
            "\n",
            "   Grinding spindle current L3_rate100000_clipping0_batch0  \\\n",
            "0                                           0.000294         \n",
            "1                                           0.000295         \n",
            "2                                           0.000310         \n",
            "3                                           0.000312         \n",
            "4                                           0.000292         \n",
            "\n",
            "            timestamp  label  \n",
            "0 2024-02-14 22:00:10      0  \n",
            "1 2024-02-14 22:04:13      0  \n",
            "2 2024-02-14 22:05:15      0  \n",
            "3 2024-02-14 22:03:43      0  \n",
            "4 2024-02-14 22:01:11      0  \n",
            "\n",
            "Combined 2000KHz Data Sample (Mean):\n",
            "   AEKi_rate2000000_clipping0_batch0           timestamp  label\n",
            "0                          -0.001509 2024-02-14 22:00:10      0\n",
            "1                          -0.000890 2024-02-14 22:04:13      0\n",
            "2                          -0.000840 2024-02-14 22:05:15      0\n",
            "3                          -0.001179 2024-02-14 22:03:43      0\n",
            "4                          -0.001196 2024-02-14 22:01:11      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Separate features and labels for 100KHz data\n",
        "features_100KHz = all_100KHzdata.drop(columns=['timestamp', 'label'])  # Exclude timestamp and label\n",
        "timestamps_100KHz = all_100KHzdata['timestamp']\n",
        "labels_100KHz = all_100KHzdata['label']\n",
        "\n",
        "# Normalize features for 100KHz data\n",
        "scaler_100KHz = StandardScaler()\n",
        "normalized_features_100KHz = scaler_100KHz.fit_transform(features_100KHz)\n",
        "\n",
        "# Combine normalized features with timestamps and labels\n",
        "normalized_100KHzdata = pd.DataFrame(normalized_features_100KHz, columns=features_100KHz.columns)\n",
        "normalized_100KHzdata.insert(0, 'timestamp', timestamps_100KHz)  # Add timestamp column back\n",
        "normalized_100KHzdata['label'] = labels_100KHz.values  # Add label column back\n",
        "\n",
        "# Separate features and labels for 2000KHz data\n",
        "features_2000KHz = all_2000KHzdata.drop(columns=['timestamp', 'label'])  # Exclude timestamp and label\n",
        "timestamps_2000KHz = all_2000KHzdata['timestamp']\n",
        "labels_2000KHz = all_2000KHzdata['label']\n",
        "\n",
        "# Normalize features for 2000KHz data\n",
        "scaler_2000KHz = StandardScaler()\n",
        "normalized_features_2000KHz = scaler_2000KHz.fit_transform(features_2000KHz)\n",
        "\n",
        "# Combine normalized features with timestamps and labels\n",
        "normalized_2000KHzdata = pd.DataFrame(normalized_features_2000KHz, columns=features_2000KHz.columns)\n",
        "normalized_2000KHzdata.insert(0, 'timestamp', timestamps_2000KHz)  # Add timestamp column back\n",
        "normalized_2000KHzdata['label'] = labels_2000KHz.values  # Add label column back\n",
        "\n",
        "print(\"Normalized 100KHz Data Sample:\")\n",
        "print(normalized_100KHzdata.head())\n",
        "print(len(normalized_100KHzdata))\n",
        "print(\"\\nNormalized 2000KHz Data Sample:\")\n",
        "print(normalized_2000KHzdata.head())\n",
        "print(len(normalized_2000KHzdata))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgO0ITh1VzAz",
        "outputId": "14088978-0e8e-4dcf-917d-457e95dd6202"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized 100KHz Data Sample:\n",
            "            timestamp  Irms_Grinding_rate100000_clipping0_batch0  \\\n",
            "0 2024-02-14 22:00:10                                  -1.213932   \n",
            "1 2024-02-14 22:04:13                                  -1.059871   \n",
            "2 2024-02-14 22:05:15                                  -1.014171   \n",
            "3 2024-02-14 22:03:43                                  -1.082180   \n",
            "4 2024-02-14 22:01:11                                  -1.185769   \n",
            "\n",
            "   Grinding spindle current L1_rate100000_clipping0_batch0  \\\n",
            "0                                           0.410776         \n",
            "1                                           1.275351         \n",
            "2                                           0.286297         \n",
            "3                                          -0.208334         \n",
            "4                                           1.423043         \n",
            "\n",
            "   Grinding spindle current L2_rate100000_clipping0_batch0  \\\n",
            "0                                          -0.126537         \n",
            "1                                           1.918509         \n",
            "2                                           0.143756         \n",
            "3                                           0.938269         \n",
            "4                                           1.256994         \n",
            "\n",
            "   Grinding spindle current L3_rate100000_clipping0_batch0  label  \n",
            "0                                          -0.436171            0  \n",
            "1                                          -0.403926            0  \n",
            "2                                           0.565636            0  \n",
            "3                                           0.652915            0  \n",
            "4                                          -0.601523            0  \n",
            "58\n",
            "\n",
            "Normalized 2000KHz Data Sample:\n",
            "            timestamp  AEKi_rate2000000_clipping0_batch0  label\n",
            "0 2024-02-14 22:00:10                          -1.575957      0\n",
            "1 2024-02-14 22:04:13                          -0.388929      0\n",
            "2 2024-02-14 22:05:15                          -0.294156      0\n",
            "3 2024-02-14 22:03:43                          -0.943421      0\n",
            "4 2024-02-14 22:01:11                          -0.974924      0\n",
            "58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Concatenate the 100KHz and 2000KHz data\n",
        "normalized_100KHzdata = normalized_100KHzdata.set_index('timestamp')\n",
        "normalized_2000KHzdata = normalized_2000KHzdata.set_index('timestamp')\n",
        "\n",
        "# Concatenate along columns\n",
        "combined_data = pd.concat([normalized_100KHzdata, normalized_2000KHzdata], axis=1, join='inner').reset_index()\n",
        "\n",
        "# Remove duplicate 'label' columns and keep the first one\n",
        "combined_data = combined_data.loc[:, ~combined_data.columns.duplicated()]\n",
        "\n",
        "# Ensure the label column is at the end\n",
        "label = combined_data.pop('label')\n",
        "combined_data['label'] = label\n",
        "\n",
        "print(\"Combined Data Sample:\")\n",
        "print(combined_data.head())\n",
        "print(len(combined_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THmE8kM0V20I",
        "outputId": "e45581ec-b153-4920-efc9-58e91d2cad11"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Data Sample:\n",
            "            timestamp  Irms_Grinding_rate100000_clipping0_batch0  \\\n",
            "0 2024-02-14 22:00:10                                  -1.213932   \n",
            "1 2024-02-14 22:04:13                                  -1.059871   \n",
            "2 2024-02-14 22:05:15                                  -1.014171   \n",
            "3 2024-02-14 22:03:43                                  -1.082180   \n",
            "4 2024-02-14 22:01:11                                  -1.185769   \n",
            "\n",
            "   Grinding spindle current L1_rate100000_clipping0_batch0  \\\n",
            "0                                           0.410776         \n",
            "1                                           1.275351         \n",
            "2                                           0.286297         \n",
            "3                                          -0.208334         \n",
            "4                                           1.423043         \n",
            "\n",
            "   Grinding spindle current L2_rate100000_clipping0_batch0  \\\n",
            "0                                          -0.126537         \n",
            "1                                           1.918509         \n",
            "2                                           0.143756         \n",
            "3                                           0.938269         \n",
            "4                                           1.256994         \n",
            "\n",
            "   Grinding spindle current L3_rate100000_clipping0_batch0  \\\n",
            "0                                          -0.436171         \n",
            "1                                          -0.403926         \n",
            "2                                           0.565636         \n",
            "3                                           0.652915         \n",
            "4                                          -0.601523         \n",
            "\n",
            "   AEKi_rate2000000_clipping0_batch0  label  \n",
            "0                          -1.575957      0  \n",
            "1                          -0.388929      0  \n",
            "2                          -0.294156      0  \n",
            "3                          -0.943421      0  \n",
            "4                          -0.974924      0  \n",
            "58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import Loss\n",
        "\n",
        "class CustomLoss(Loss):\n",
        "    def __init__(self, name=\"custom_loss\"):\n",
        "        super().__init__(name=name)\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        main_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
        "        auxiliary_loss = self.calculate_auxiliary_loss(y_true, y_pred)\n",
        "        total_loss = main_loss + auxiliary_loss\n",
        "        return total_loss\n",
        "\n",
        "    def calculate_auxiliary_loss(self, y_true, y_pred):\n",
        "        mse_loss = tf.keras.losses.mean_squared_error(y_true, y_pred)"
      ],
      "metadata": {
        "id": "sG47xniZV6QR"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_decision_forests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-ZVTTgxMp7F",
        "outputId": "3aa2ad4e-3a14-4da4-9a07-491cda9d79ee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_decision_forests in /usr/local/lib/python3.10/dist-packages (1.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (2.0.3)\n",
            "Requirement already satisfied: tensorflow~=2.16.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (2.16.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.16.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (0.43.0)\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (3.1.1)\n",
            "Requirement already satisfied: tf-keras~=2.16 in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (2.16.0)\n",
            "Requirement already satisfied: ydf in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (0.4.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (2.16.2)\n",
            "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (3.3.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (0.37.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2024.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow~=2.16.1->tensorflow_decision_forests) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow~=2.16.1->tensorflow_decision_forests) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow~=2.16.1->tensorflow_decision_forests) (0.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow~=2.16.1->tensorflow_decision_forests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow~=2.16.1->tensorflow_decision_forests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow~=2.16.1->tensorflow_decision_forests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow~=2.16.1->tensorflow_decision_forests) (2024.6.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow~=2.16.1->tensorflow_decision_forests) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow~=2.16.1->tensorflow_decision_forests) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow~=2.16.1->tensorflow_decision_forests) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow~=2.16.1->tensorflow_decision_forests) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow~=2.16.1->tensorflow_decision_forests) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow~=2.16.1->tensorflow_decision_forests) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow~=2.16.1->tensorflow_decision_forests) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/decision_forests/tutorials/beginner_colab\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "\n",
        "# without 'timestamp'\n",
        "ndf = combined_data.loc[:, combined_data.columns != 'timestamp']\n",
        "\n",
        "# rename?\n",
        "\n",
        "#  tf_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(ndf, label = 'label')\n",
        "\n",
        "#  model = tfdf.keras.RandomForestModel()\n",
        "#  model.fit(tf_dataset)\n",
        "\n",
        "#  print(model.summary())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G074VnE3a18M",
        "outputId": "6fa22fdc-0b1b-4a65-fea1-4bde913672d9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmphwko7i1k as temporary training directory\n",
            "Reading training dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x795c46796b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset read in 0:00:00.289120. Found 58 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.045389\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x795c3df380d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"random_forest_model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 1 (1.00 Byte)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 1 (1.00 Byte)\n",
            "_________________________________________________________________\n",
            "Type: \"RANDOM_FOREST\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (5):\n",
            "\tAEKi_rate2000000_clipping0_batch0\n",
            "\tGrinding_spindle_current_L1_rate100000_clipping0_batch0\n",
            "\tGrinding_spindle_current_L2_rate100000_clipping0_batch0\n",
            "\tGrinding_spindle_current_L3_rate100000_clipping0_batch0\n",
            "\tIrms_Grinding_rate100000_clipping0_batch0\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
            "    1. \"Irms_Grinding_rate100000_clipping0_batch0\"  0.675676 ################\n",
            "    2.         \"AEKi_rate2000000_clipping0_batch0\"  0.657895 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1. \"Irms_Grinding_rate100000_clipping0_batch0\" 156.000000 ################\n",
            "    2.         \"AEKi_rate2000000_clipping0_batch0\" 144.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1. \"Irms_Grinding_rate100000_clipping0_batch0\" 156.000000 ################\n",
            "    2.         \"AEKi_rate2000000_clipping0_batch0\" 144.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1. \"Irms_Grinding_rate100000_clipping0_batch0\" 6191.562926 ################\n",
            "    2.         \"AEKi_rate2000000_clipping0_batch0\" 5716.991736 \n",
            "\n",
            "\n",
            "\n",
            "Winner takes all: true\n",
            "Out-of-bag evaluation: accuracy:1 logloss:0.0162503\n",
            "Number of trees: 300\n",
            "Total number of nodes: 900\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 300 Average: 3 StdDev: 0\n",
            "Min: 3 Max: 3 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 3, 3] 300 100.00% 100.00% ##########\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 600 Average: 1 StdDev: 0\n",
            "Min: 1 Max: 1 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 1, 1] 600 100.00% 100.00% ##########\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 600 Average: 29 StdDev: 3.81925\n",
            "Min: 18 Max: 40 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 18, 19)  1   0.17%   0.17%\n",
            "[ 19, 20)  3   0.50%   0.67%\n",
            "[ 20, 21)  2   0.33%   1.00%\n",
            "[ 21, 22) 14   2.33%   3.33% ##\n",
            "[ 22, 23)  8   1.33%   4.67% #\n",
            "[ 23, 24) 18   3.00%   7.67% ##\n",
            "[ 24, 26) 54   9.00%  16.67% #######\n",
            "[ 26, 27) 48   8.00%  24.67% ######\n",
            "[ 27, 28) 70  11.67%  36.33% #########\n",
            "[ 28, 29) 56   9.33%  45.67% #######\n",
            "[ 29, 30) 52   8.67%  54.33% #######\n",
            "[ 30, 31) 56   9.33%  63.67% #######\n",
            "[ 31, 32) 70  11.67%  75.33% #########\n",
            "[ 32, 34) 77  12.83%  88.17% ##########\n",
            "[ 34, 35) 25   4.17%  92.33% ###\n",
            "[ 35, 36) 18   3.00%  95.33% ##\n",
            "[ 36, 37)  8   1.33%  96.67% #\n",
            "[ 37, 38) 14   2.33%  99.00% ##\n",
            "[ 38, 39)  2   0.33%  99.33%\n",
            "[ 39, 40]  4   0.67% 100.00% #\n",
            "\n",
            "Attribute in nodes:\n",
            "\t156 : Irms_Grinding_rate100000_clipping0_batch0 [NUMERICAL]\n",
            "\t144 : AEKi_rate2000000_clipping0_batch0 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t156 : Irms_Grinding_rate100000_clipping0_batch0 [NUMERICAL]\n",
            "\t144 : AEKi_rate2000000_clipping0_batch0 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t156 : Irms_Grinding_rate100000_clipping0_batch0 [NUMERICAL]\n",
            "\t144 : AEKi_rate2000000_clipping0_batch0 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t156 : Irms_Grinding_rate100000_clipping0_batch0 [NUMERICAL]\n",
            "\t144 : AEKi_rate2000000_clipping0_batch0 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t156 : Irms_Grinding_rate100000_clipping0_batch0 [NUMERICAL]\n",
            "\t144 : AEKi_rate2000000_clipping0_batch0 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t156 : Irms_Grinding_rate100000_clipping0_batch0 [NUMERICAL]\n",
            "\t144 : AEKi_rate2000000_clipping0_batch0 [NUMERICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t300 : HigherCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t300 : HigherCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t300 : HigherCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t300 : HigherCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t300 : HigherCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t300 : HigherCondition\n",
            "Node format: NOT_SET\n",
            "\n",
            "Training OOB:\n",
            "\ttrees: 1, Out-of-bag evaluation: accuracy:1 logloss:0\n",
            "\ttrees: 11, Out-of-bag evaluation: accuracy:1 logloss:0.0121605\n",
            "\ttrees: 21, Out-of-bag evaluation: accuracy:0.982759 logloss:0.0146086\n",
            "\ttrees: 31, Out-of-bag evaluation: accuracy:1 logloss:0.0119508\n",
            "\ttrees: 41, Out-of-bag evaluation: accuracy:1 logloss:0.00992007\n",
            "\ttrees: 51, Out-of-bag evaluation: accuracy:1 logloss:0.0111487\n",
            "\ttrees: 61, Out-of-bag evaluation: accuracy:1 logloss:0.0116701\n",
            "\ttrees: 71, Out-of-bag evaluation: accuracy:1 logloss:0.0111553\n",
            "\ttrees: 81, Out-of-bag evaluation: accuracy:1 logloss:0.010371\n",
            "\ttrees: 91, Out-of-bag evaluation: accuracy:1 logloss:0.0106567\n",
            "\ttrees: 101, Out-of-bag evaluation: accuracy:1 logloss:0.0116349\n",
            "\ttrees: 111, Out-of-bag evaluation: accuracy:1 logloss:0.0127286\n",
            "\ttrees: 121, Out-of-bag evaluation: accuracy:1 logloss:0.0133617\n",
            "\ttrees: 131, Out-of-bag evaluation: accuracy:1 logloss:0.0131477\n",
            "\ttrees: 141, Out-of-bag evaluation: accuracy:1 logloss:0.0124717\n",
            "\ttrees: 151, Out-of-bag evaluation: accuracy:1 logloss:0.0129083\n",
            "\ttrees: 161, Out-of-bag evaluation: accuracy:1 logloss:0.0123873\n",
            "\ttrees: 171, Out-of-bag evaluation: accuracy:1 logloss:0.0135826\n",
            "\ttrees: 181, Out-of-bag evaluation: accuracy:1 logloss:0.013189\n",
            "\ttrees: 191, Out-of-bag evaluation: accuracy:1 logloss:0.013187\n",
            "\ttrees: 201, Out-of-bag evaluation: accuracy:1 logloss:0.0139865\n",
            "\ttrees: 211, Out-of-bag evaluation: accuracy:1 logloss:0.0144167\n",
            "\ttrees: 221, Out-of-bag evaluation: accuracy:1 logloss:0.01525\n",
            "\ttrees: 231, Out-of-bag evaluation: accuracy:1 logloss:0.0152656\n",
            "\ttrees: 241, Out-of-bag evaluation: accuracy:1 logloss:0.0149041\n",
            "\ttrees: 251, Out-of-bag evaluation: accuracy:1 logloss:0.015349\n",
            "\ttrees: 261, Out-of-bag evaluation: accuracy:1 logloss:0.0156088\n",
            "\ttrees: 271, Out-of-bag evaluation: accuracy:1 logloss:0.0159937\n",
            "\ttrees: 281, Out-of-bag evaluation: accuracy:1 logloss:0.0161213\n",
            "\ttrees: 291, Out-of-bag evaluation: accuracy:1 logloss:0.0161924\n",
            "\ttrees: 300, Out-of-bag evaluation: accuracy:1 logloss:0.0162503\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ndf.columns\n",
        "ndf.head(3)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "zFW25dL0g-7T",
        "outputId": "b3cee73d-2aa9-473c-ddb0-38d0d7cea3bf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Irms_Grinding_rate100000_clipping0_batch0  \\\n",
              "0                                  -1.213932   \n",
              "1                                  -1.059871   \n",
              "2                                  -1.014171   \n",
              "\n",
              "   Grinding spindle current L1_rate100000_clipping0_batch0  \\\n",
              "0                                           0.410776         \n",
              "1                                           1.275351         \n",
              "2                                           0.286297         \n",
              "\n",
              "   Grinding spindle current L2_rate100000_clipping0_batch0  \\\n",
              "0                                          -0.126537         \n",
              "1                                           1.918509         \n",
              "2                                           0.143756         \n",
              "\n",
              "   Grinding spindle current L3_rate100000_clipping0_batch0  \\\n",
              "0                                          -0.436171         \n",
              "1                                          -0.403926         \n",
              "2                                           0.565636         \n",
              "\n",
              "   AEKi_rate2000000_clipping0_batch0  label  \n",
              "0                          -1.575957      0  \n",
              "1                          -0.388929      0  \n",
              "2                          -0.294156      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49054024-a073-4dbc-9c86-d46363f4d480\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Irms_Grinding_rate100000_clipping0_batch0</th>\n",
              "      <th>Grinding spindle current L1_rate100000_clipping0_batch0</th>\n",
              "      <th>Grinding spindle current L2_rate100000_clipping0_batch0</th>\n",
              "      <th>Grinding spindle current L3_rate100000_clipping0_batch0</th>\n",
              "      <th>AEKi_rate2000000_clipping0_batch0</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.213932</td>\n",
              "      <td>0.410776</td>\n",
              "      <td>-0.126537</td>\n",
              "      <td>-0.436171</td>\n",
              "      <td>-1.575957</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.059871</td>\n",
              "      <td>1.275351</td>\n",
              "      <td>1.918509</td>\n",
              "      <td>-0.403926</td>\n",
              "      <td>-0.388929</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.014171</td>\n",
              "      <td>0.286297</td>\n",
              "      <td>0.143756</td>\n",
              "      <td>0.565636</td>\n",
              "      <td>-0.294156</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49054024-a073-4dbc-9c86-d46363f4d480')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-49054024-a073-4dbc-9c86-d46363f4d480 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-49054024-a073-4dbc-9c86-d46363f4d480');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ab3a9f41-77db-4f6f-8583-0e8ebce9f6d6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ab3a9f41-77db-4f6f-8583-0e8ebce9f6d6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ab3a9f41-77db-4f6f-8583-0e8ebce9f6d6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ndf",
              "summary": "{\n  \"name\": \"ndf\",\n  \"rows\": 58,\n  \"fields\": [\n    {\n      \"column\": \"Irms_Grinding_rate100000_clipping0_batch0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0087337902782492,\n        \"min\": -1.2340298478042369,\n        \"max\": 1.283166550722637,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          -1.2139319943759497,\n          -1.1765053428150536,\n          0.8794113911250451\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Grinding spindle current L1_rate100000_clipping0_batch0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0087337902782494,\n        \"min\": -2.1785584895012775,\n        \"max\": 1.8865975325674036,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          0.41077587921895353,\n          -0.11775303333939542,\n          1.0120682226614788\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Grinding spindle current L2_rate100000_clipping0_batch0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0087337902782492,\n        \"min\": -1.7694350450589302,\n        \"max\": 2.4560705137529775,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          -0.12653687215087256,\n          -1.1570975602410212,\n          -0.3524467424149106\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Grinding spindle current L3_rate100000_clipping0_batch0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0087337902782492,\n        \"min\": -2.225978480627361,\n        \"max\": 2.239199379752336,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          -0.4361707378241623,\n          -1.2458378470128095,\n          -1.7934792783181126\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AEKi_rate2000000_clipping0_batch0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0087337902782492,\n        \"min\": -1.997556081931452,\n        \"max\": 1.9752767115772678,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          -1.575956717529845,\n          -1.4412519438057911,\n          1.2960640813849713\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encode the categorical labels as integers\n",
        "label = 'label'\n",
        "\n",
        "classes = ndf[label].unique().tolist()\n",
        "print(f\"Label clsses: {classes}\")\n",
        "\n",
        "ndf[label] = ndf[label].map(classes.index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPEPuXZ7h3NE",
        "outputId": "d6748ab4-b234-4e58-e2ee-22647a0d0409"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label clsses: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-074a6774b075>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ndf[label] = ndf[label].map(classes.index)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the dataset into training and testing\n",
        "import numpy as np\n",
        "def split_dataset(dataset, test_ratio=0.30):\n",
        "  \"\"\"Splits a panda dataframe in two.\"\"\"\n",
        "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
        "  return dataset[~test_indices], dataset[test_indices]\n",
        "\n",
        "\n",
        "train_ds_pd, test_ds_pd = split_dataset(ndf)\n",
        "print(\"{} examples in training, {} examples for testing.\".format(\n",
        "    len(train_ds_pd), len(test_ds_pd)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTdu32NEehQi",
        "outputId": "71d1e3b8-010d-40a9-ed10-b0301edeeae4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44 examples in training, 14 examples for testing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the pandas dataframe into tensorflow datasets\n",
        "\n",
        "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label = label)\n",
        "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label = label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-WUcnIJdxj8",
        "outputId": "14b89b5d-391b-4942-c610-a43161cde30e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# specify the model\n",
        "rf_model = tfdf.keras.RandomForestModel(verbose = 2)\n",
        "\n",
        "# train the model\n",
        "rf_model.fit(train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_ZROHonjjp_",
        "outputId": "e62871c1-4d3d-42fd-a401-434629cd0642"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use 2 thread(s) for training\n",
            "Use /tmp/tmp9b144ym0 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training tensor examples:\n",
            "Features: {'Irms_Grinding_rate100000_clipping0_batch0': <tf.Tensor 'data:0' shape=(None,) dtype=float64>, 'Grinding_spindle_current_L1_rate100000_clipping0_batch0': <tf.Tensor 'data_1:0' shape=(None,) dtype=float64>, 'Grinding_spindle_current_L2_rate100000_clipping0_batch0': <tf.Tensor 'data_2:0' shape=(None,) dtype=float64>, 'Grinding_spindle_current_L3_rate100000_clipping0_batch0': <tf.Tensor 'data_3:0' shape=(None,) dtype=float64>, 'AEKi_rate2000000_clipping0_batch0': <tf.Tensor 'data_4:0' shape=(None,) dtype=float64>}\n",
            "Label: Tensor(\"data_5:0\", shape=(None,), dtype=int64)\n",
            "Weights: None\n",
            "Normalized tensor features:\n",
            " {'Irms_Grinding_rate100000_clipping0_batch0': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast:0' shape=(None,) dtype=float32>), 'Grinding_spindle_current_L1_rate100000_clipping0_batch0': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_1:0' shape=(None,) dtype=float32>), 'Grinding_spindle_current_L2_rate100000_clipping0_batch0': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_2:0' shape=(None,) dtype=float32>), 'Grinding_spindle_current_L3_rate100000_clipping0_batch0': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_3:0' shape=(None,) dtype=float32>), 'AEKi_rate2000000_clipping0_batch0': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_4:0' shape=(None,) dtype=float32>)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel._consumes_training_examples_until_eof at 0x795c46796b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset read in 0:00:00.441208. Found 44 examples.\n",
            "Training model...\n",
            "Standard output detected as not visible to the user e.g. running in a notebook. Creating a training log redirection. If training gets stuck, try calling tfdf.keras.set_training_logs_redirection(False).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO 24-06-17 19:01:59.6224 UTC kernel.cc:771] Start Yggdrasil model training\n",
            "[INFO 24-06-17 19:01:59.6346 UTC kernel.cc:772] Collect training examples\n",
            "[INFO 24-06-17 19:01:59.6346 UTC kernel.cc:785] Dataspec guide:\n",
            "column_guides {\n",
            "  column_name_pattern: \"^__LABEL$\"\n",
            "  type: CATEGORICAL\n",
            "  categorial {\n",
            "    min_vocab_frequency: 0\n",
            "    max_vocab_count: -1\n",
            "  }\n",
            "}\n",
            "default_column_guide {\n",
            "  categorial {\n",
            "    max_vocab_count: 2000\n",
            "  }\n",
            "  discretized_numerical {\n",
            "    maximum_num_bins: 255\n",
            "  }\n",
            "}\n",
            "ignore_columns_without_guides: false\n",
            "detect_numerical_as_discretized_numerical: false\n",
            "\n",
            "[INFO 24-06-17 19:01:59.6348 UTC kernel.cc:391] Number of batches: 1\n",
            "[INFO 24-06-17 19:01:59.6348 UTC kernel.cc:392] Number of examples: 44\n",
            "[INFO 24-06-17 19:01:59.6348 UTC kernel.cc:792] Training dataset:\n",
            "Number of records: 44\n",
            "Number of columns: 6\n",
            "\n",
            "Number of columns by type:\n",
            "\tNUMERICAL: 5 (83.3333%)\n",
            "\tCATEGORICAL: 1 (16.6667%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "NUMERICAL: 5 (83.3333%)\n",
            "\t0: \"AEKi_rate2000000_clipping0_batch0\" NUMERICAL mean:-0.0760535 min:-1.99756 max:1.97528 sd:0.979253\n",
            "\t1: \"Grinding_spindle_current_L1_rate100000_clipping0_batch0\" NUMERICAL mean:0.00546475 min:-2.17856 max:1.8866 sd:1.07649\n",
            "\t2: \"Grinding_spindle_current_L2_rate100000_clipping0_batch0\" NUMERICAL mean:-0.166095 min:-1.76944 max:2.45607 sd:0.965715\n",
            "\t3: \"Grinding_spindle_current_L3_rate100000_clipping0_batch0\" NUMERICAL mean:-0.148995 min:-2.22598 max:2.2392 sd:0.925385\n",
            "\t4: \"Irms_Grinding_rate100000_clipping0_batch0\" NUMERICAL mean:-0.0505113 min:-1.21393 max:1.28317 sd:0.98726\n",
            "\n",
            "CATEGORICAL: 1 (16.6667%)\n",
            "\t5: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO 24-06-17 19:01:59.6349 UTC kernel.cc:808] Configure learner\n",
            "[INFO 24-06-17 19:01:59.6351 UTC kernel.cc:822] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"^AEKi_rate2000000_clipping0_batch0$\"\n",
            "features: \"^Grinding_spindle_current_L1_rate100000_clipping0_batch0$\"\n",
            "features: \"^Grinding_spindle_current_L2_rate100000_clipping0_batch0$\"\n",
            "features: \"^Grinding_spindle_current_L3_rate100000_clipping0_batch0$\"\n",
            "features: \"^Irms_Grinding_rate100000_clipping0_batch0$\"\n",
            "label: \"^__LABEL$\"\n",
            "task: CLASSIFICATION\n",
            "random_seed: 123456\n",
            "metadata {\n",
            "  framework: \"TF Keras\"\n",
            "}\n",
            "pure_serving_model: false\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 300\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    keep_non_leaf_label_distribution: true\n",
            "    num_candidate_attributes: 0\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "    uplift {\n",
            "      min_examples_in_treatment: 5\n",
            "      split_score: KULLBACK_LEIBLER\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  num_oob_variable_importances_permutations: 1\n",
            "  bootstrap_training_dataset: true\n",
            "  bootstrap_size_ratio: 1\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "  sampling_with_replacement: true\n",
            "}\n",
            "\n",
            "[INFO 24-06-17 19:01:59.6353 UTC kernel.cc:825] Deployment config:\n",
            "cache_path: \"/tmp/tmp9b144ym0/working_cache\"\n",
            "num_threads: 2\n",
            "try_resume_training: true\n",
            "\n",
            "[INFO 24-06-17 19:01:59.6363 UTC kernel.cc:887] Train model\n",
            "[INFO 24-06-17 19:01:59.6366 UTC random_forest.cc:416] Training random forest on 44 example(s) and 5 feature(s).\n",
            "[INFO 24-06-17 19:01:59.6434 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:1 logloss:0\n",
            "[INFO 24-06-17 19:01:59.6438 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:1 logloss:0.0258962\n",
            "[INFO 24-06-17 19:01:59.6442 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:1 logloss:0.0291121\n",
            "[INFO 24-06-17 19:01:59.6446 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:1 logloss:0.0284719\n",
            "[INFO 24-06-17 19:01:59.6449 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:1 logloss:0.0267042\n",
            "[INFO 24-06-17 19:01:59.6453 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:1 logloss:0.0249476\n",
            "[INFO 24-06-17 19:01:59.6457 UTC random_forest.cc:802] Training of tree  61/300 (tree index:61) done accuracy:1 logloss:0.0301909\n",
            "[INFO 24-06-17 19:01:59.6460 UTC random_forest.cc:802] Training of tree  71/300 (tree index:71) done accuracy:1 logloss:0.0275214\n",
            "[INFO 24-06-17 19:01:59.6466 UTC random_forest.cc:802] Training of tree  81/300 (tree index:81) done accuracy:1 logloss:0.0254575\n",
            "[INFO 24-06-17 19:01:59.6469 UTC random_forest.cc:802] Training of tree  91/300 (tree index:91) done accuracy:1 logloss:0.0272599\n",
            "[INFO 24-06-17 19:01:59.6473 UTC random_forest.cc:802] Training of tree  101/300 (tree index:101) done accuracy:1 logloss:0.0239112\n",
            "[INFO 24-06-17 19:01:59.6476 UTC random_forest.cc:802] Training of tree  111/300 (tree index:111) done accuracy:1 logloss:0.0232446\n",
            "[INFO 24-06-17 19:01:59.6480 UTC random_forest.cc:802] Training of tree  121/300 (tree index:121) done accuracy:1 logloss:0.0256855\n",
            "[INFO 24-06-17 19:01:59.6484 UTC random_forest.cc:802] Training of tree  131/300 (tree index:131) done accuracy:1 logloss:0.0249073\n",
            "[INFO 24-06-17 19:01:59.6487 UTC random_forest.cc:802] Training of tree  141/300 (tree index:141) done accuracy:1 logloss:0.023141\n",
            "[INFO 24-06-17 19:01:59.6580 UTC random_forest.cc:802] Training of tree  151/300 (tree index:151) done accuracy:1 logloss:0.0224727\n",
            "[INFO 24-06-17 19:01:59.6585 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:1 logloss:0.0221976\n",
            "[INFO 24-06-17 19:01:59.6589 UTC random_forest.cc:802] Training of tree  171/300 (tree index:171) done accuracy:1 logloss:0.0218932\n",
            "[INFO 24-06-17 19:01:59.6635 UTC random_forest.cc:802] Training of tree  181/300 (tree index:181) done accuracy:1 logloss:0.021618\n",
            "[INFO 24-06-17 19:01:59.6638 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:1 logloss:0.02121\n",
            "[INFO 24-06-17 19:01:59.6640 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:1 logloss:0.0205108\n",
            "[INFO 24-06-17 19:01:59.6642 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.977273 logloss:0.0221246\n",
            "[INFO 24-06-17 19:01:59.6645 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.977273 logloss:0.0218501\n",
            "[INFO 24-06-17 19:01:59.6656 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:1 logloss:0.021077\n",
            "[INFO 24-06-17 19:01:59.6659 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.977273 logloss:0.0218901\n",
            "[INFO 24-06-17 19:01:59.6663 UTC random_forest.cc:802] Training of tree  251/300 (tree index:251) done accuracy:0.977273 logloss:0.0219502\n",
            "[INFO 24-06-17 19:01:59.6667 UTC random_forest.cc:802] Training of tree  261/300 (tree index:261) done accuracy:0.977273 logloss:0.0217083\n",
            "[INFO 24-06-17 19:01:59.6671 UTC random_forest.cc:802] Training of tree  271/300 (tree index:271) done accuracy:0.977273 logloss:0.0220488\n",
            "[INFO 24-06-17 19:01:59.6675 UTC random_forest.cc:802] Training of tree  281/300 (tree index:281) done accuracy:0.977273 logloss:0.0215435\n",
            "[INFO 24-06-17 19:01:59.6678 UTC random_forest.cc:802] Training of tree  291/300 (tree index:291) done accuracy:0.977273 logloss:0.0216643\n",
            "[INFO 24-06-17 19:01:59.6698 UTC random_forest.cc:802] Training of tree  300/300 (tree index:250) done accuracy:0.977273 logloss:0.0221275\n",
            "[INFO 24-06-17 19:01:59.6699 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.977273 logloss:0.0221275\n",
            "[INFO 24-06-17 19:01:59.6701 UTC kernel.cc:919] Export model in log directory: /tmp/tmp9b144ym0 with prefix 20f116a4cf034d2c\n",
            "[INFO 24-06-17 19:01:59.6720 UTC kernel.cc:937] Save model in resources\n",
            "[INFO 24-06-17 19:01:59.6768 UTC abstract_model.cc:883] Model self evaluation:\n",
            "Number of predictions (without weights): 44\n",
            "Number of predictions (with weights): 44\n",
            "Task: CLASSIFICATION\n",
            "Label: __LABEL\n",
            "\n",
            "Accuracy: 0.977273  CI95[W][0.896665 0.998835]\n",
            "LogLoss: : 0.0221275\n",
            "ErrorRate: : 0.0227273\n",
            "\n",
            "Default Accuracy: : 0.522727\n",
            "Default LogLoss: : 0.692114\n",
            "Default ErrorRate: : 0.477273\n",
            "\n",
            "Confusion Table:\n",
            "truth\\prediction\n",
            "    1   2\n",
            "1  22   1\n",
            "2   0  21\n",
            "Total: 44\n",
            "\n",
            "\n",
            "[INFO 24-06-17 19:01:59.6913 UTC kernel.cc:1233] Loading model from path /tmp/tmp9b144ym0/model/ with prefix 20f116a4cf034d2c\n",
            "[INFO 24-06-17 19:01:59.6995 UTC decision_forest.cc:734] Model loaded with 300 root(s), 900 node(s), and 2 input feature(s).\n",
            "[INFO 24-06-17 19:01:59.6996 UTC abstract_model.cc:1362] Engine \"RandomForestOptPred\" built\n",
            "[INFO 24-06-17 19:01:59.6996 UTC kernel.cc:1061] Use fast generic engine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained in 0:00:00.107252\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x795c3c5b3760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x795c3dfd0370>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "rf_model.compile(metrics = [\"accuracy\"])\n",
        "# rf_model.compile(optimizer = 'adam', loss = CustomLoss(), metrics = ['accuracy'])\n",
        "evaluation = rf_model.evaluate(test_ds, return_dict = True)\n",
        "print()\n",
        "\n",
        "for name, value in evaluation.items():\n",
        "  print(f\"{name}: {value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HXhKgeylEgU",
        "outputId": "3290bedc-0312-4559-955e-af42c3a43ded"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 270ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "\n",
            "loss: 0.0000\n",
            "accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "# from sklearn.decomposition import PCA\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import r2_score\n",
        "\n",
        "# import tensorflow as tf\n",
        "# import tensorflow_decision_forests as tfdf\n",
        "\n",
        "# combined_data.columns\n",
        "# without 'timestamp'\n",
        "#features = ['Irms_Grinding_rate100000_clipping0_batch0',\n",
        "#      'Grinding spindle current L1_rate100000_clipping0_batch0',\n",
        "#       'Grinding spindle current L2_rate100000_clipping0_batch0',\n",
        "#       'Grinding spindle current L3_rate100000_clipping0_batch0',\n",
        "#       'AEKi_rate2000000_clipping0_batch0']\n",
        "#target = ['label']\n",
        "\n",
        "# X = combined_data[features]\n",
        "# y = combined_data[target]\n",
        "\n",
        "# splitting train and test data\n",
        "# X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size = .3, random_state = 42)\n",
        "\n",
        "# PCA ?\n",
        "# pca = PCA().fit(X_tr)\n",
        "# X_tr = pca.transform(X_tr)\n",
        "# X_ts = pca.transform(X_ts)\n",
        "\n",
        "# Random Forest\n",
        "#train_dataset = tf.data.Dataset.from_tensor_slices((X_tr, y_tr))\n",
        "# train_dataset = train_dataset.batch(30)\n",
        "\n",
        "# tfrf = tfdf.keras.RandomForestModel(tfdf.keras.Task.CLASSIFICATION)\n",
        "# tfrf.compile(optimizer = 'adam', loss = '', metrics = ['accuracy'])\n",
        "# tfrf.fit(train_dataset)\n",
        "\n",
        "# print(tfrf.summary())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We3yPMwZZZBh",
        "outputId": "fe556756-ff5a-4669-aab3-c7b3045f500d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmp16z5twkq as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.214928. Found 40 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.031662\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "Model: \"random_forest_model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 1 (1.00 Byte)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 1 (1.00 Byte)\n",
            "_________________________________________________________________\n",
            "Type: \"RANDOM_FOREST\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (5):\n",
            "\tdata:0.0\n",
            "\tdata:0.1\n",
            "\tdata:0.2\n",
            "\tdata:0.3\n",
            "\tdata:0.4\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
            "    1. \"data:0.0\"  0.684932 ################\n",
            "    2. \"data:0.4\"  0.649351 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1. \"data:0.0\" 162.000000 ################\n",
            "    2. \"data:0.4\" 138.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1. \"data:0.0\" 162.000000 ################\n",
            "    2. \"data:0.4\" 138.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1. \"data:0.0\" 4400.885906 ################\n",
            "    2. \"data:0.4\" 3744.032254 \n",
            "\n",
            "\n",
            "\n",
            "Winner takes all: true\n",
            "Out-of-bag evaluation: accuracy:1 logloss:0.0271454\n",
            "Number of trees: 300\n",
            "Total number of nodes: 900\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 300 Average: 3 StdDev: 0\n",
            "Min: 3 Max: 3 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 3, 3] 300 100.00% 100.00% ##########\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 600 Average: 1 StdDev: 0\n",
            "Min: 1 Max: 1 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 1, 1] 600 100.00% 100.00% ##########\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 600 Average: 20 StdDev: 3.36749\n",
            "Min: 9 Max: 31 Ignored: 0\n",
            "----------------------------------------------\n",
            "[  9, 10)  1   0.17%   0.17%\n",
            "[ 10, 11)  1   0.17%   0.33%\n",
            "[ 11, 12)  1   0.17%   0.50%\n",
            "[ 12, 13)  9   1.50%   2.00% #\n",
            "[ 13, 14)  6   1.00%   3.00% #\n",
            "[ 14, 15) 10   1.67%   4.67% #\n",
            "[ 15, 17) 62  10.33%  15.00% ########\n",
            "[ 17, 18) 38   6.33%  21.33% #####\n",
            "[ 18, 19) 67  11.17%  32.50% #########\n",
            "[ 19, 20) 70  11.67%  44.17% #########\n",
            "[ 20, 21) 70  11.67%  55.83% #########\n",
            "[ 21, 22) 70  11.67%  67.50% #########\n",
            "[ 22, 23) 67  11.17%  78.67% #########\n",
            "[ 23, 25) 78  13.00%  91.67% ##########\n",
            "[ 25, 26) 22   3.67%  95.33% ###\n",
            "[ 26, 27) 10   1.67%  97.00% #\n",
            "[ 27, 28)  6   1.00%  98.00% #\n",
            "[ 28, 29)  9   1.50%  99.50% #\n",
            "[ 29, 30)  1   0.17%  99.67%\n",
            "[ 30, 31]  2   0.33% 100.00%\n",
            "\n",
            "Attribute in nodes:\n",
            "\t162 : data:0.0 [NUMERICAL]\n",
            "\t138 : data:0.4 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t162 : data:0.0 [NUMERICAL]\n",
            "\t138 : data:0.4 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t162 : data:0.0 [NUMERICAL]\n",
            "\t138 : data:0.4 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t162 : data:0.0 [NUMERICAL]\n",
            "\t138 : data:0.4 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t162 : data:0.0 [NUMERICAL]\n",
            "\t138 : data:0.4 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t162 : data:0.0 [NUMERICAL]\n",
            "\t138 : data:0.4 [NUMERICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t300 : HigherCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t300 : HigherCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t300 : HigherCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t300 : HigherCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t300 : HigherCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t300 : HigherCondition\n",
            "Node format: NOT_SET\n",
            "\n",
            "Training OOB:\n",
            "\ttrees: 1, Out-of-bag evaluation: accuracy:1 logloss:0\n",
            "\ttrees: 11, Out-of-bag evaluation: accuracy:0.974359 logloss:0.0234946\n",
            "\ttrees: 21, Out-of-bag evaluation: accuracy:1 logloss:0.0236115\n",
            "\ttrees: 31, Out-of-bag evaluation: accuracy:1 logloss:0.021505\n",
            "\ttrees: 41, Out-of-bag evaluation: accuracy:1 logloss:0.0219638\n",
            "\ttrees: 51, Out-of-bag evaluation: accuracy:1 logloss:0.0223146\n",
            "\ttrees: 61, Out-of-bag evaluation: accuracy:1 logloss:0.0231609\n",
            "\ttrees: 71, Out-of-bag evaluation: accuracy:1 logloss:0.0218205\n",
            "\ttrees: 81, Out-of-bag evaluation: accuracy:1 logloss:0.0216679\n",
            "\ttrees: 91, Out-of-bag evaluation: accuracy:1 logloss:0.0205312\n",
            "\ttrees: 101, Out-of-bag evaluation: accuracy:1 logloss:0.0215755\n",
            "\ttrees: 111, Out-of-bag evaluation: accuracy:1 logloss:0.0211662\n",
            "\ttrees: 121, Out-of-bag evaluation: accuracy:1 logloss:0.0219444\n",
            "\ttrees: 131, Out-of-bag evaluation: accuracy:1 logloss:0.0225428\n",
            "\ttrees: 141, Out-of-bag evaluation: accuracy:1 logloss:0.0219529\n",
            "\ttrees: 151, Out-of-bag evaluation: accuracy:1 logloss:0.0219971\n",
            "\ttrees: 161, Out-of-bag evaluation: accuracy:1 logloss:0.022981\n",
            "\ttrees: 171, Out-of-bag evaluation: accuracy:1 logloss:0.0225334\n",
            "\ttrees: 181, Out-of-bag evaluation: accuracy:1 logloss:0.023802\n",
            "\ttrees: 191, Out-of-bag evaluation: accuracy:1 logloss:0.0245323\n",
            "\ttrees: 201, Out-of-bag evaluation: accuracy:1 logloss:0.0249643\n",
            "\ttrees: 211, Out-of-bag evaluation: accuracy:1 logloss:0.0274454\n",
            "\ttrees: 221, Out-of-bag evaluation: accuracy:1 logloss:0.027678\n",
            "\ttrees: 231, Out-of-bag evaluation: accuracy:1 logloss:0.0282327\n",
            "\ttrees: 241, Out-of-bag evaluation: accuracy:1 logloss:0.0285058\n",
            "\ttrees: 251, Out-of-bag evaluation: accuracy:1 logloss:0.0280112\n",
            "\ttrees: 261, Out-of-bag evaluation: accuracy:1 logloss:0.0262271\n",
            "\ttrees: 271, Out-of-bag evaluation: accuracy:1 logloss:0.0268594\n",
            "\ttrees: 281, Out-of-bag evaluation: accuracy:1 logloss:0.0269819\n",
            "\ttrees: 291, Out-of-bag evaluation: accuracy:1 logloss:0.0266022\n",
            "\ttrees: 300, Out-of-bag evaluation: accuracy:1 logloss:0.0271454\n",
            "\n",
            "None\n"
          ]
        }
      ]
    }
  ]
}